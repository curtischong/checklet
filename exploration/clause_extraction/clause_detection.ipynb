{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d214d773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 inserting                                                                      \n",
      "     ________________________________|______________________________________________________________             \n",
      "    |      |   |   |   |                   categorizing                                             |           \n",
      "    |      |   |   |   |     ___________________|_____________________                              |            \n",
      "    |      |   |   |   |    |        |          |                     by                            |           \n",
      "    |      |   |   |   |    |        |          |                     |                             |            \n",
      "    |      |   |   |   |    |        |          |                  creating                      deployed       \n",
      "    |      |   |   |   |    |        |          |              _______|_________             _______|_______     \n",
      "    |      |   |   |   |    |       from        |           email               |        service            |   \n",
      "    |      |   |   |   |    |        |          |         ____|_______          |      _____|_______        |    \n",
      "    |      |   |   |   |    |     clients       in       |        monitoring    |     |             on      |   \n",
      "    |      |   |   |   |    |        |          |        |            |         |     |             |       |    \n",
      "    |      |   |   |   |  emails    200        CRM       |           API      using   |           Cloud    with \n",
      "    |      |   |   |   |    |        |          |        |            |         |     |             |       |    \n",
      "Automated and  ,  and  .   20k+     over        a        an          REST    Express the          Azure   Docker\n",
      "\n",
      "2\n",
      "3 categorizing 20k+ emails from over 200 clients in a CRM by creating an email monitoring REST API using Express\n",
      "\n",
      "24 deployed the service on Azure Cloud with Docker\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/65227103/clause-extraction-long-sentence-segmentation-in-python\n",
    "\n",
    "\n",
    "import spacy\n",
    "import deplacy\n",
    "from nltk import Tree\n",
    "en = spacy.load('en_core_web_md')\n",
    "\n",
    "#text = \"This all encompassing experience wore off for a moment and in that moment, my awareness came gasping to the surface of the hallucination and I was able to consider momentarily that I had killed myself by taking an outrageous dose of an online drug and this was the most pathetic death experience of all time.\"\n",
    "text = \"Automated inserting and categorizing 20k+ emails from over 200 clients in a CRM by creating an email monitoring REST API using Express, and deployed the service on Azure Cloud with Docker.\"\n",
    "#text = \"he plays cricket but does not play hockey.\"\n",
    "\n",
    "doc = en(text)\n",
    "#deplacy.render(doc)\n",
    "def to_nltk_tree(node):\n",
    "    if node.n_lefts + node.n_rights > 0:\n",
    "        return Tree(node.orth_, [to_nltk_tree(child) for child in node.children])\n",
    "    else:\n",
    "        return node.orth_\n",
    "\n",
    "[to_nltk_tree(sent.root).pretty_print() for sent in doc.sents]\n",
    "\n",
    "seen = set() # keep track of covered words\n",
    "\n",
    "chunks = []\n",
    "for sent in doc.sents:\n",
    "    #[print(str(x) + \"~\") for x in sent.root.children]\n",
    "    heads = [cc for cc in sent.root.children if cc.dep_ in ['conj', 'adp']]\n",
    "    print(len(heads))\n",
    "\n",
    "    for head in heads:\n",
    "        words = [ww for ww in head.subtree]\n",
    "        for word in words:\n",
    "            seen.add(word)\n",
    "        chunk = (' '.join([ww.text for ww in words]))\n",
    "        chunks.append( (head.i, chunk) )\n",
    "\n",
    "    # this last piece of code is a really lazy way to print the remaining chars and\n",
    "    # saying that it's a clause, when in fact it isn't\n",
    "    #unseen = [ww for ww in sent if ww not in seen]\n",
    "    #chunk = ' '.join([ww.text for ww in unseen])\n",
    "    #chunks.append( (sent.root.i, chunk) )\n",
    "\n",
    "chunks = sorted(chunks, key=lambda x: x[0])\n",
    "\n",
    "for ii, chunk in chunks:\n",
    "    print(ii, chunk, end=\"\\n\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2676fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                plays                 \n",
      "  ________________|_________           \n",
      " |     |     |    |        play       \n",
      " |     |     |    |     ____|_____     \n",
      " he cricket but   .   does not  hockey\n",
      "\n",
      "he\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'spacy.tokens.span.Span' object has no attribute '_dep'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m sent:\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;28mprint\u001b[39m(token)\n\u001b[0;32m---> 30\u001b[0m         \u001b[38;5;28mprint\u001b[39m(token, \u001b[43msent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dep\u001b[49m)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ii, chunk \u001b[38;5;129;01min\u001b[39;00m chunks:\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28mprint\u001b[39m(ii, chunk, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'spacy.tokens.span.Span' object has no attribute '_dep'"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/65227103/clause-extraction-long-sentence-segmentation-in-python\n",
    "\n",
    "\n",
    "import spacy\n",
    "import deplacy\n",
    "from nltk import Tree\n",
    "en = spacy.load('en_core_web_md')\n",
    "\n",
    "#text = \"This all encompassing experience wore off for a moment and in that moment, my awareness came gasping to the surface of the hallucination and I was able to consider momentarily that I had killed myself by taking an outrageous dose of an online drug and this was the most pathetic death experience of all time.\"\n",
    "#text = \"Automated inserting and categorizing 20k+ emails from over 200 clients in a CRM by creating an email monitoring REST API using Express, and deployed the service on Azure Cloud with Docker.\"\n",
    "text = \"he plays cricket but does not play hockey.\"\n",
    "\n",
    "doc = en(text)\n",
    "#deplacy.render(doc)\n",
    "def to_nltk_tree(node):\n",
    "    if node.n_lefts + node.n_rights > 0:\n",
    "        return Tree(node.orth_, [to_nltk_tree(child) for child in node.children])\n",
    "    else:\n",
    "        return node.orth_\n",
    "\n",
    "[to_nltk_tree(sent.root).pretty_print() for sent in doc.sents]\n",
    "\n",
    "seen = set() # keep track of covered words\n",
    "\n",
    "chunks = []\n",
    "for sent in doc.sents:\n",
    "    #[print(str(x) + \"~\") for x in sent.root.children]\n",
    "    for token in sent:\n",
    "        print(token)\n",
    "        print(token, sent._dep)\n",
    "\n",
    "for ii, chunk in chunks:\n",
    "    print(ii, chunk, end=\"\\n\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e8fa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy.explain(\"ADP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbf2f37",
   "metadata": {},
   "source": [
    "### Stanford Core NLP\n",
    "download from https://stanfordnlp.github.io/CoreNLP/\n",
    "\n",
    "then run \n",
    "\n",
    "`cd /Users/curtis/Desktop/idioms/pkg/stanford-corenlp-4.1.0;\n",
    "java -mx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 15000`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffdd11f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://github.com/rahulkg31/sentence-to-clauses/blob/master/sent_to_clauses.py\n",
    "import nltk\n",
    "import re\n",
    "from nltk.tree import ParentedTree\n",
    "from pycorenlp import *\n",
    "# start the connection here\n",
    "nlp=StanfordCoreNLP(\"http://0.0.0.0:9000/\")\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "600a62a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num clauses: 3\n",
      "- deployed the service on Azure Cloud with Docker\n",
      "\n",
      "- REST API using Express\n",
      "\n",
      "- inserting and categorizing 20k emails from over 200 clients in a CRM by creating an email monitoring\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get verb phrases\n",
    "# if one \"VP\" node has 2 or more \"VP\" children then\n",
    "# all child \"VP\" while be used as verb phrases\n",
    "# since a clause may have more than one verb phrases\n",
    "# ex:- he plays cricket but does not play hockey\n",
    "# here two verb phrases are \"plays cricket\" and \"does not play hockey\"\n",
    "#                       ROOT\n",
    "#                        |\n",
    "#                        S\n",
    "#   _____________________|____\n",
    "#  |                          VP\n",
    "#  |          ________________|____\n",
    "#  |         |           |         VP\n",
    "#  |         |           |     ____|________\n",
    "#  |         VP          |    |    |        VP\n",
    "#  |     ____|_____      |    |    |    ____|____\n",
    "#  NP   |          NP    |    |    |   |         NP\n",
    "#  |    |          |     |    |    |   |         |\n",
    "# PRP  VBZ         NN    CC  VBZ   RB  VB        NN\n",
    "#  |    |          |     |    |    |   |         |\n",
    "# 1\n",
    "def get_verb_phrases(t):\n",
    "    verb_phrases = []\n",
    "    num_children = len(t)\n",
    "    num_VP = sum(1 if t[i].label() == \"VP\" else 0 for i in range(0, num_children))\n",
    "\n",
    "    if t.label() != \"VP\":\n",
    "        for i in range(0, num_children):\n",
    "            if t[i].height() > 2:\n",
    "                verb_phrases.extend(get_verb_phrases(t[i]))\n",
    "    elif t.label() == \"VP\" and num_VP > 1:\n",
    "        for i in range(0, num_children):\n",
    "            if t[i].label() == \"VP\":\n",
    "                if t[i].height() > 2:\n",
    "                    verb_phrases.extend(get_verb_phrases(t[i]))\n",
    "    else:\n",
    "        verb_phrases.append(' '.join(t.leaves()))\n",
    "\n",
    "    return verb_phrases\n",
    "\n",
    "# get position of first node \"VP\" while traversing from top to bottom\n",
    "# get the position of subordinating conjunctions like after, as, before, if, since, while etc\n",
    "# delete the node at these positions to get the subject\n",
    "# first delete vp nodes then subordinating conjunction nodes\n",
    "# ie, get the part without verb phrases\n",
    "# in the above example \"he\" will be returned\n",
    "def get_pos(t):\n",
    "    vp_pos = []\n",
    "    sub_conj_pos = []\n",
    "    num_children = len(t)\n",
    "    children = [t[i].label() for i in range(0,num_children)]\n",
    "\n",
    "    flag = re.search(r\"(S|SBAR|SBARQ|SINV|SQ)\", ' '.join(children))\n",
    "\n",
    "    if \"VP\" in children and not flag:\n",
    "        for i in range(0, num_children):\n",
    "            if t[i].label() == \"VP\":\n",
    "                vp_pos.append(t[i].treeposition())\n",
    "    elif not \"VP\" in children and not flag:\n",
    "        for i in range(0, num_children):\n",
    "            if t[i].height() > 2:\n",
    "                temp1,temp2 = get_pos(t[i])\n",
    "                vp_pos.extend(temp1)\n",
    "                sub_conj_pos.extend(temp2)\n",
    "    # comment this \"else\" part, if want to include subordinating conjunctions\n",
    "    else:\n",
    "        for i in range(0, num_children):\n",
    "            if t[i].label() in [\"S\",\"SBAR\",\"SBARQ\",\"SINV\",\"SQ\"]:\n",
    "                temp1, temp2 = get_pos(t[i])\n",
    "                vp_pos.extend(temp1)\n",
    "                sub_conj_pos.extend(temp2)\n",
    "            else:\n",
    "                sub_conj_pos.append(t[i].treeposition())\n",
    "\n",
    "    return (vp_pos,sub_conj_pos)\n",
    "\n",
    "\n",
    "# get all clauses\n",
    "def get_clause_list(sent):\n",
    "    parser = nlp.annotate(sent, properties={\"annotators\":\"parse\",\"outputFormat\": \"json\"})\n",
    "    parser=json.loads(parser)\n",
    "    #print(parser[\"sentences\"][0][\"parse\"])\n",
    "    sent_tree = ParentedTree.fromstring(parser[\"sentences\"][0][\"parse\"])\n",
    "    clause_level_list = [\"S\",\"SBAR\",\"SBARQ\",\"SINV\",\"SQ\"]\n",
    "    clause_list = []\n",
    "    sub_trees = []\n",
    "    # sent_tree.pretty_print()\n",
    "\n",
    "    # break the tree into subtrees of clauses using\n",
    "    # clause levels \"S\",\"SBAR\",\"SBARQ\",\"SINV\",\"SQ\"\n",
    "    for sub_tree in reversed(list(sent_tree.subtrees())):\n",
    "        #print(sub_tree.label())\n",
    "        if sub_tree.label() in clause_level_list:\n",
    "            if sub_tree.parent().label() in clause_level_list:\n",
    "                continue\n",
    "            if (len(sub_tree) == 1 and sub_tree.label() == \"S\" and sub_tree[0].label() == \"VP\"\n",
    "                and not sub_tree.parent().label() in clause_level_list):\n",
    "                continue\n",
    "\n",
    "            sub_trees.append(sub_tree)\n",
    "            del sent_tree[sub_tree.treeposition()]\n",
    "\n",
    "    # for each clause level subtree, extract relevant simple sentence\n",
    "    for t in sub_trees:\n",
    "        # get verb phrases from the new modified tree\n",
    "        verb_phrases = get_verb_phrases(t)\n",
    "\n",
    "        # get tree without verb phrases (mainly subject)\n",
    "        # remove subordinating conjunctions\n",
    "        vp_pos,sub_conj_pos = get_pos(t)\n",
    "        for i in vp_pos:\n",
    "            del t[i]\n",
    "        for i in sub_conj_pos:\n",
    "            del t[i]\n",
    "        #print(t.label())\n",
    "\n",
    "        # I commented this out so we don't attch the subject to each phrase\n",
    "        subject_phrase = \"\"#' '.join(t.leaves())\n",
    "\n",
    "        # update the clause_list\n",
    "        for i in verb_phrases:\n",
    "            clause_list.append(subject_phrase + \" \" + i)\n",
    "\n",
    "    clause_list.reverse()\n",
    "    return clause_list\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "    # sent = \"he plays cricket but does not play hockey\"\n",
    "    # sent = re.sub(r\"(\\.|,|\\?|\\(|\\)|\\[|\\])\",\" \",sent)\n",
    "    # clause_qlist = get_clause_list(sent)\n",
    "    # print(clause_list)\n",
    "#while (True):\n",
    "#sent = input(\"sentence : \\n \")\n",
    "sent = \"Automated inserting and categorizing 20k+ emails from over 200 clients in a CRM by creating an email monitoring REST API using Express, and deployed the service on Azure Cloud with Docker.\"\n",
    "#sent = \"he plays cricket but does not play hockey\"\n",
    "#sent = re.sub(r\"(\\.|,|\\?|\\(|\\)|\\[|\\])\", \" \", sent)\n",
    "clauses = get_clause_list(sent)\n",
    "print(\"num clauses:\", len(clauses))\n",
    "for clause in clauses:\n",
    "    print(\"-\" + clause,end=\"\\n\\n\")\n",
    "#NOTE: sentences must end in a period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab030e61",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (900021613.py, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [11]\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(cur.leaves())\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "        # S = Simple declarative clause\n",
    "        # SBar = Subordinate Clause\n",
    "        # SBARQ = Direct question introduced by wh-element\n",
    "        # SINV = Declarative sentence with subject-aux inversion\n",
    "        # SQ = Yes/no questions and subconstituent of SBARQ excluding wh-element\n",
    "sent = \"he plays cricket but does not play hockey.\"\n",
    "parser = nlp.annotate(sent, properties={\"annotators\": \"parse\", \"outputFormat\": \"json\"})\n",
    "parser = json.loads(parser)\n",
    "sent_tree = ParentedTree.fromstring(parser[\"sentences\"][0][\"parse\"])\n",
    "for cur in sent_tree.subtrees():\n",
    "    if cur.label in [\"S\",\"SBAR\",\"SBARQ\",\"SINV\",\"SQ\", \"PP\"]:\n",
    "        print(cur.leaves())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eea3725",
   "metadata": {},
   "source": [
    "input: sentence\n",
    "output: clauses\n",
    "\n",
    "clause:{\n",
    "    verb phrase:\n",
    "    subject:\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0258293",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46624a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = nlp.annotate(sent, properties={\"annotators\":\"parse\",\"outputFormat\": \"json\"})\n",
    "parser=json.loads(parser)\n",
    "#print(parser[\"sentences\"][0][\"parse\"])\n",
    "sent_tree = ParentedTree.fromstring(parser[\"sentences\"][0][\"parse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28403ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(. .)\n",
      "['.']\n",
      "(NNP Docker)\n",
      "['Docker']\n",
      "(NP (NNP Docker))\n",
      "['Docker']\n",
      "(IN with)\n",
      "['with']\n",
      "(PP (IN with) (NP (NNP Docker)))\n",
      "['with', 'Docker']\n",
      "(NNP Cloud)\n",
      "['Cloud']\n",
      "(NNP Azure)\n",
      "['Azure']\n",
      "(NP (NNP Azure) (NNP Cloud))\n",
      "['Azure', 'Cloud']\n",
      "(NP (NP (NNP Azure) (NNP Cloud)) (PP (IN with) (NP (NNP Docker))))\n",
      "['Azure', 'Cloud', 'with', 'Docker']\n",
      "(IN on)\n",
      "['on']\n",
      "(PP\n",
      "  (IN on)\n",
      "  (NP (NP (NNP Azure) (NNP Cloud)) (PP (IN with) (NP (NNP Docker)))))\n",
      "['on', 'Azure', 'Cloud', 'with', 'Docker']\n",
      "(NN service)\n",
      "['service']\n",
      "(DT the)\n",
      "['the']\n",
      "(NP (DT the) (NN service))\n",
      "['the', 'service']\n",
      "(VBD deployed)\n",
      "['deployed']\n",
      "(VP\n",
      "  (VBD deployed)\n",
      "  (NP (DT the) (NN service))\n",
      "  (PP\n",
      "    (IN on)\n",
      "    (NP\n",
      "      (NP (NNP Azure) (NNP Cloud))\n",
      "      (PP (IN with) (NP (NNP Docker))))))\n",
      "['deployed', 'the', 'service', 'on', 'Azure', 'Cloud', 'with', 'Docker']\n",
      "(CC and)\n",
      "['and']\n",
      "(, ,)\n",
      "[',']\n",
      "(NNP Express)\n",
      "['Express']\n",
      "(NP (NNP Express))\n",
      "['Express']\n",
      "(VBG using)\n",
      "['using']\n",
      "(VP (VBG using) (NP (NNP Express)))\n",
      "['using', 'Express']\n",
      "(S (VP (VBG using) (NP (NNP Express))))\n",
      "['using', 'Express']\n",
      "(NN API)\n",
      "['API']\n",
      "(NP (NN API))\n",
      "['API']\n",
      "(VBD REST)\n",
      "['REST']\n",
      "(VP (VBD REST) (NP (NN API)) (S (VP (VBG using) (NP (NNP Express)))))\n",
      "['REST', 'API', 'using', 'Express']\n",
      "(VP\n",
      "  (VP\n",
      "    (VBD REST)\n",
      "    (NP (NN API))\n",
      "    (S (VP (VBG using) (NP (NNP Express)))))\n",
      "  (, ,)\n",
      "  (CC and)\n",
      "  (VP\n",
      "    (VBD deployed)\n",
      "    (NP (DT the) (NN service))\n",
      "    (PP\n",
      "      (IN on)\n",
      "      (NP\n",
      "        (NP (NNP Azure) (NNP Cloud))\n",
      "        (PP (IN with) (NP (NNP Docker)))))))\n",
      "['REST', 'API', 'using', 'Express', ',', 'and', 'deployed', 'the', 'service', 'on', 'Azure', 'Cloud', 'with', 'Docker']\n",
      "(NN monitoring)\n",
      "['monitoring']\n",
      "(NN email)\n",
      "['email']\n",
      "(DT an)\n",
      "['an']\n",
      "(NP (DT an) (NN email) (NN monitoring))\n",
      "['an', 'email', 'monitoring']\n",
      "(VBG creating)\n",
      "['creating']\n",
      "(VP (VBG creating) (NP (DT an) (NN email) (NN monitoring)))\n",
      "['creating', 'an', 'email', 'monitoring']\n",
      "(S (VP (VBG creating) (NP (DT an) (NN email) (NN monitoring))))\n",
      "['creating', 'an', 'email', 'monitoring']\n",
      "(IN by)\n",
      "['by']\n",
      "(PP\n",
      "  (IN by)\n",
      "  (S (VP (VBG creating) (NP (DT an) (NN email) (NN monitoring)))))\n",
      "['by', 'creating', 'an', 'email', 'monitoring']\n",
      "(NNP CRM)\n",
      "['CRM']\n",
      "(DT a)\n",
      "['a']\n",
      "(NP (DT a) (NNP CRM))\n",
      "['a', 'CRM']\n",
      "(IN in)\n",
      "['in']\n",
      "(PP (IN in) (NP (DT a) (NNP CRM)))\n",
      "['in', 'a', 'CRM']\n",
      "(NNS clients)\n",
      "['clients']\n",
      "(CD 200)\n",
      "['200']\n",
      "(RB over)\n",
      "['over']\n",
      "(QP (RB over) (CD 200))\n",
      "['over', '200']\n",
      "(NP (QP (RB over) (CD 200)) (NNS clients))\n",
      "['over', '200', 'clients']\n",
      "(NP\n",
      "  (NP (QP (RB over) (CD 200)) (NNS clients))\n",
      "  (PP (IN in) (NP (DT a) (NNP CRM))))\n",
      "['over', '200', 'clients', 'in', 'a', 'CRM']\n",
      "(IN from)\n",
      "['from']\n",
      "(PP\n",
      "  (IN from)\n",
      "  (NP\n",
      "    (NP (QP (RB over) (CD 200)) (NNS clients))\n",
      "    (PP (IN in) (NP (DT a) (NNP CRM)))))\n",
      "['from', 'over', '200', 'clients', 'in', 'a', 'CRM']\n",
      "(NNS emails)\n",
      "['emails']\n",
      "(JJ 20k)\n",
      "['20k']\n",
      "(NP (JJ 20k) (NNS emails))\n",
      "['20k', 'emails']\n",
      "(VBG categorizing)\n",
      "['categorizing']\n",
      "(CC and)\n",
      "['and']\n",
      "(VBG inserting)\n",
      "['inserting']\n",
      "(VP\n",
      "  (VBG inserting)\n",
      "  (CC and)\n",
      "  (VBG categorizing)\n",
      "  (NP (JJ 20k) (NNS emails))\n",
      "  (PP\n",
      "    (IN from)\n",
      "    (NP\n",
      "      (NP (QP (RB over) (CD 200)) (NNS clients))\n",
      "      (PP (IN in) (NP (DT a) (NNP CRM)))))\n",
      "  (PP\n",
      "    (IN by)\n",
      "    (S (VP (VBG creating) (NP (DT an) (NN email) (NN monitoring))))))\n",
      "['inserting', 'and', 'categorizing', '20k', 'emails', 'from', 'over', '200', 'clients', 'in', 'a', 'CRM', 'by', 'creating', 'an', 'email', 'monitoring']\n",
      "(NNP Automated)\n",
      "['Automated']\n",
      "(NP (NNP Automated))\n",
      "['Automated']\n",
      "(NP\n",
      "  (NP (NNP Automated))\n",
      "  (VP\n",
      "    (VBG inserting)\n",
      "    (CC and)\n",
      "    (VBG categorizing)\n",
      "    (NP (JJ 20k) (NNS emails))\n",
      "    (PP\n",
      "      (IN from)\n",
      "      (NP\n",
      "        (NP (QP (RB over) (CD 200)) (NNS clients))\n",
      "        (PP (IN in) (NP (DT a) (NNP CRM)))))\n",
      "    (PP\n",
      "      (IN by)\n",
      "      (S (VP (VBG creating) (NP (DT an) (NN email) (NN monitoring)))))))\n",
      "['Automated', 'inserting', 'and', 'categorizing', '20k', 'emails', 'from', 'over', '200', 'clients', 'in', 'a', 'CRM', 'by', 'creating', 'an', 'email', 'monitoring']\n",
      "(S\n",
      "  (NP\n",
      "    (NP (NNP Automated))\n",
      "    (VP\n",
      "      (VBG inserting)\n",
      "      (CC and)\n",
      "      (VBG categorizing)\n",
      "      (NP (JJ 20k) (NNS emails))\n",
      "      (PP\n",
      "        (IN from)\n",
      "        (NP\n",
      "          (NP (QP (RB over) (CD 200)) (NNS clients))\n",
      "          (PP (IN in) (NP (DT a) (NNP CRM)))))\n",
      "      (PP\n",
      "        (IN by)\n",
      "        (S\n",
      "          (VP (VBG creating) (NP (DT an) (NN email) (NN monitoring)))))))\n",
      "  (VP\n",
      "    (VP\n",
      "      (VBD REST)\n",
      "      (NP (NN API))\n",
      "      (S (VP (VBG using) (NP (NNP Express)))))\n",
      "    (, ,)\n",
      "    (CC and)\n",
      "    (VP\n",
      "      (VBD deployed)\n",
      "      (NP (DT the) (NN service))\n",
      "      (PP\n",
      "        (IN on)\n",
      "        (NP\n",
      "          (NP (NNP Azure) (NNP Cloud))\n",
      "          (PP (IN with) (NP (NNP Docker)))))))\n",
      "  (. .))\n",
      "['Automated', 'inserting', 'and', 'categorizing', '20k', 'emails', 'from', 'over', '200', 'clients', 'in', 'a', 'CRM', 'by', 'creating', 'an', 'email', 'monitoring', 'REST', 'API', 'using', 'Express', ',', 'and', 'deployed', 'the', 'service', 'on', 'Azure', 'Cloud', 'with', 'Docker', '.']\n",
      "(ROOT\n",
      "  (S\n",
      "    (NP\n",
      "      (NP (NNP Automated))\n",
      "      (VP\n",
      "        (VBG inserting)\n",
      "        (CC and)\n",
      "        (VBG categorizing)\n",
      "        (NP (JJ 20k) (NNS emails))\n",
      "        (PP\n",
      "          (IN from)\n",
      "          (NP\n",
      "            (NP (QP (RB over) (CD 200)) (NNS clients))\n",
      "            (PP (IN in) (NP (DT a) (NNP CRM)))))\n",
      "        (PP\n",
      "          (IN by)\n",
      "          (S\n",
      "            (VP\n",
      "              (VBG creating)\n",
      "              (NP (DT an) (NN email) (NN monitoring)))))))\n",
      "    (VP\n",
      "      (VP\n",
      "        (VBD REST)\n",
      "        (NP (NN API))\n",
      "        (S (VP (VBG using) (NP (NNP Express)))))\n",
      "      (, ,)\n",
      "      (CC and)\n",
      "      (VP\n",
      "        (VBD deployed)\n",
      "        (NP (DT the) (NN service))\n",
      "        (PP\n",
      "          (IN on)\n",
      "          (NP\n",
      "            (NP (NNP Azure) (NNP Cloud))\n",
      "            (PP (IN with) (NP (NNP Docker)))))))\n",
      "    (. .)))\n",
      "['Automated', 'inserting', 'and', 'categorizing', '20k', 'emails', 'from', 'over', '200', 'clients', 'in', 'a', 'CRM', 'by', 'creating', 'an', 'email', 'monitoring', 'REST', 'API', 'using', 'Express', ',', 'and', 'deployed', 'the', 'service', 'on', 'Azure', 'Cloud', 'with', 'Docker', '.']\n"
     ]
    }
   ],
   "source": [
    "def parse_clauses(sent):\n",
    "    parser = nlp.annotate(sent, properties={\"annotators\":\"parse\",\"outputFormat\": \"json\"})\n",
    "    parser=json.loads(parser)\n",
    "    #print(parser[\"sentences\"][0][\"parse\"])\n",
    "    sent_tree = ParentedTree.fromstring(parser[\"sentences\"][0][\"parse\"])\n",
    "    clause_level_list = [\"S\",\"SBAR\",\"SBARQ\",\"SINV\",\"SQ\"]\n",
    "    clause_list = []\n",
    "    sub_trees = []\n",
    "    # sent_tree.pretty_print()\n",
    "\n",
    "    # break the tree into subtrees of clauses using\n",
    "    # clause levels \"S\",\"SBAR\",\"SBARQ\",\"SINV\",\"SQ\"\n",
    "    for sub_tree in reversed(list(sent_tree.subtrees())):\n",
    "        print(sub_tree)\n",
    "        print(sub_tree.leaves())\n",
    "    \n",
    "    #if \"VP\" in children and not flag:\n",
    "    #    for i in range(0, num_children):\n",
    "    #        if t[i].label() == \"VP\":\n",
    "    #            vp_pos.append(t[i].treeposition())\n",
    "parse_clauses(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dff2d3c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'parser' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mparser\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentences\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(parser[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentences\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparse\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'parser' is not defined"
     ]
    }
   ],
   "source": [
    "print(parser[\"sentences\"][0].keys())\n",
    "print(parser[\"sentences\"][0][\"parse\"])\n",
    "#print(sent_tree)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

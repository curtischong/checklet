{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 (https://huggingface.co/sshleifer/distilbart-cnn-12-6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': ' This is'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': ' Designed and'}]\n"
     ]
    }
   ],
   "source": [
    "print(summarizer(\n",
    "    \"designed and implemented\",\n",
    "    min_length=2, max_length=5))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/72486821/summarization-with-huggingface-how-to-generate-one-word-at-a-time\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# Load model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sshleifer/distilbart-xsum-1-1\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"sshleifer/distilbart-xsum-1-1\")\n",
    "\n",
    "text = \"The branch of Artificial Intelligence, Natural Language Processing (NLP), is all about making machines understand and process human language. Processing human language is not an easy task for machines as machines work with numbers and not text. ðŸ’» NLP is such a vast and widely studied branch of AI that every now and then we hear a new advancement in this domain. Researchers are trying hard to make the machines understand human language and the context behind it.\"\n",
    "\n",
    "# Tokenize text\n",
    "batch = tokenizer(text, return_tensors=\"pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "generated_sequence = torch.tensor([[tokenizer.sep_token_id]])  # initial token\n",
    "\n",
    "# Generation loop\n",
    "while True:\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids=batch[\"input_ids\"], decoder_input_ids=generated_sequence)\n",
    "    next_token_logits = output.logits[:, -1, :]\n",
    "    next_token_scores = next_token_logits.softmax(dim=-1)\n",
    "\n",
    "    # Take token with highest probability\n",
    "    next_token = next_token_scores.argmax().unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "    # Append token to generated sequence\n",
    "    generated_sequence = torch.cat((generated_sequence, next_token), dim=1)\n",
    "    # Stop if EOS token generated\n",
    "    if (generated_sequence.squeeze()[-1] == tokenizer.eos_token_id):\n",
    "        break\n",
    "\n",
    "summary = tokenizer.batch_decode(generated_sequence, skip_special_tokens=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "[\" The world's largest language language in the world, according to a new study.\"]"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': ' The branch of Artificial Intelligence, Natural Language Processing (NLP), is all about making machines understand and process human language . Processing human language is not an easy task for machines as machines work'}]\n"
     ]
    }
   ],
   "source": [
    "print(summarizer(text, min_length=2, max_length=40))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}